{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41286307-9e9d-482a-b6f2-03ea7e4839e9",
   "metadata": {},
   "source": [
    "# Challenge: Bear1 - Data Investigation\n",
    "\n",
    "In the rapidly evolving field of AI security, the ability to scrutinize and interpret data is indispensable. Whether it's identifying potential security threats, understanding anomalous behavior, or uncovering hidden patterns, the insights gained from data investigation are pivotal in developing robust AI systems that are secure and resilient against adversarial attacks.\n",
    "\n",
    "This challenge is crafted to introduce you to the world of offensive AI security through a hands-on approach. By participating, you will:\n",
    "\n",
    "- **Gain practical experience with pandas**, a powerful Python library for data analysis, enabling you to manipulate and explore datasets efficiently.\n",
    "- **Learn basic techniques for data manipulation and analysis** that are essential in identifying vulnerabilities and potential threats within datasets.\n",
    "- **Discover how to extract hidden information from data**â€”a skill critical in many aspects of cybersecurity and AI security research.\n",
    "Whether you're a beginner eager to dive into the world of data analysis and AI security, or an experienced practitioner looking to sharpen your skills, this challenge offers valuable insights and techniques. Armed with the dataset provided, your task is to unveil a hidden word, employing your newfound skills in data manipulation and analysis with pandas.\n",
    "\n",
    "If this is your first time using pandas there are many resources out there to get started. You can start with a few here:\n",
    "- Official pandas documentation: https://pandas.pydata.org/docs/getting_started/index.html\n",
    "- Youtube tutorial https://www.youtube.com/watch?v=_Eb0utIRdkw"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3274133-448d-418c-b613-ed33d2d34d48",
   "metadata": {},
   "source": [
    "## Challenge Objective\n",
    "\n",
    "Lets take a look at the problem statement from the challenge as it is written:\n",
    "```\n",
    "This dataset contains historic records of the local bear population. The path to the flag is revealed by understanding the unique traits of each bear at their most expressive moments. Can you use your pandas skills to reveal the flag?\n",
    "\n",
    "The flag format is {WORD}, where WORD is what you will uncover. You will send this WORD to the score api to recieve the flag. Pay close attention to the details in your dataset and think creatively about how to interpret them.\n",
    "```\n",
    "\n",
    "We are provided a dataset that should be used for this challenge. It is provided in CSV format.\n",
    "\n",
    "To successfully navigate this challenge we must do some data analysis. We will tackle this in the following steps:\n",
    "\n",
    "1. **Understanding the Data**: Utilize pandas to load and get familiar with the dataset.\n",
    "2. **Exploratory Data Analysis (EDA)**: Perform an exploratory analysis on each column in the dataset, uncovering patterns, distributions, and unique traits.\n",
    "3. **Sorting and Filtering**: Learn techniques for sorting and filtering the dataset to isolate relevant information.\n",
    "4. **Revealing the Hidden Flag**: Synthesize our findings to identify the hidden flag within the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6661bf-a933-48c5-bb7a-0128c714f912",
   "metadata": {},
   "source": [
    "## Step 1: Setup and Downloading Data\n",
    "\n",
    "Before diving into data analysis, you'll need to download the necessary dataset for this challenge. First, retrieve your personalized API key from the challenge platform. Replace `YOUR_API_KEY` in the code below with your actual API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd26781a-3859-4f8c-a6a0-ad140fe70813",
   "metadata": {},
   "outputs": [],
   "source": [
    "CRUCIBLE_API_KEY = \"YOUR_API_KEY\"  # Replace with your actual API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fff846-dbe6-4dd9-9ff2-f14dce652328",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "artifacts = [\"bear.csv\"]\n",
    "\n",
    "for artifact in artifacts:\n",
    "    url = f\"https://dev-crucible.dreadnode.io/api/artifacts/bear/{artifact}\"\n",
    "    headers={\"Authorization\": CRUCIBLE_API_KEY}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        with open(artifact, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{artifact} was successfully downloaded\")\n",
    "    else:\n",
    "        print(f\"Failed to download {artifact}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a7406b-903b-4ac4-9c0b-ad8e92201d94",
   "metadata": {},
   "source": [
    "Once the files are downloaded, you can verify the contents of bear.csv by checking the first few lines:\n",
    "\n",
    "This will display the first 10 lines of your CSV file, which should look like this:\n",
    "\n",
    "```\n",
    "tune,bear,val\n",
    "22.55263063165446,Kodiak,p\n",
    "82.06112442587525,Grizzly,g\n",
    "94.8957988728884,Black,Q\n",
    "62.18038848300604,Panda,a\n",
    "41.19384582347789,Black,L\n",
    "11.232319965271387,Sun,X\n",
    "85.11257757600849,Panda,R\n",
    "85.69846024859997,Sloth,N\n",
    "46.777891017199,Brown,o\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac71610-a75c-44ca-8764-e8d14a560899",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head bear.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238a761-5c0a-442a-aac6-e1441e75f019",
   "metadata": {},
   "source": [
    "## Loading in Our Dataset\n",
    "\n",
    "Now, let's load the dataset into a pandas DataFrame and examine the first few rows to understand its structure better. We will use pandas' `read_csv` function for this purpose.\n",
    "\n",
    "This code sets up your data analysis environment with pandas, NumPy, and matplotlib, and loads your CSV data into a pandas DataFrame named df. Running `df.head()` will show the first five rows of your dataset, allowing you to start familiarizing yourself with the data you will be analyzing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5eab23-6873-4a32-a7c6-415c6ab8b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt # For data visualization\n",
    "\n",
    "df = pd.read_csv('bear.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ef0bd6-7d03-4b1f-8986-7bb6ac5cf9f4",
   "metadata": {},
   "source": [
    "## Step 2: Understanding the Data\n",
    "\n",
    "In this step, we will take a closer look at the dataset to understand its structure and the types of data it contains. The dataset features three columns, each representing different types of information:\n",
    "\n",
    "- `tune`: This column contains numeric data, representing some measured attribute of the bears.\n",
    "- `bear`: This column is categorical and lists types of bears.\n",
    "- `val`: A column of text characters, potentially encoding information.\n",
    "\n",
    "### Examining Data Types and Missing Values\n",
    "\n",
    "Before diving deeper, it's important to confirm the data types and check for any missing values to ensure the integrity of our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75574d24-4f1d-401a-9e56-0f88104be4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and check for missing values\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f20ff3-d98e-4113-a088-30b9c234bfa5",
   "metadata": {},
   "source": [
    "### Distribution of Numeric Data\n",
    "\n",
    "Let's visualize the distribution of the tune column to understand its range and general behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e4420-7d0f-4222-9221-e159510f075b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of 'tune'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df['tune'].plot(kind='hist', bins=25, title='Distribution of `tune` Feature')\n",
    "plt.xlabel('Tune Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8429f3c-4336-41b0-93e2-91de822a7adb",
   "metadata": {},
   "source": [
    "This histogram helps us see how the values in the tune column are distributed, potentially indicating different behaviors or traits of the bears based on this metric. We can see that the values are uniformly distributed between 0 and 100."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6a79b0-459f-4ac8-ae81-f123ca3a1d0e",
   "metadata": {},
   "source": [
    "### Analyzing Categorical Data\n",
    "\n",
    "Next, we'll explore the bear column by examining the frequency of each bear type. This can help us understand which bear types are more common in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b6a016-8585-4bf2-b032-ccc2bee0d513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the frequency of bear types\n",
    "df['bear'].value_counts().plot(kind='barh', title='Frequency of Bear Types')\n",
    "plt.xlabel('Number of Occurrences')\n",
    "plt.ylabel('Bear Type')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6bdee5-8b9e-4c13-ba6d-64fd0642dd0b",
   "metadata": {},
   "source": [
    "This bar chart provides a clear view of how many times each bear type appears, highlighting any significant imbalances in bear representation. We can see that while there are some differences in the number of rows for each bear type, no one bear appears to be significantly over or under represented."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e704dcda-bf15-44e5-8288-aeed7ccfb2e7",
   "metadata": {},
   "source": [
    "## Exploring Text Data\n",
    "\n",
    "Finally, let's explore the val column, which contains text characters. We'll look at the unique characters present, which might be crucial for uncovering hidden patterns later. Because we know the flag will be a text string, this column may be important in solving the puzzle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d415c4e-b3c9-4dbb-976b-4952e16e9bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying unique characters in the 'val' column\n",
    "unique_values = df['val'].unique()\n",
    "print(\"Unique characters in the 'val' column:\", unique_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a62fc4-60f5-4db8-a23c-afec2517af9f",
   "metadata": {},
   "source": [
    "Understanding these characters and their distribution might be key in decoding any hidden messages or flags in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cee2a4-132d-48fa-b3ad-ce15a07a2d42",
   "metadata": {},
   "source": [
    "## Step 3: Sorting and Filtering the data.\n",
    "\n",
    "In data analysis, especially in challenges like this, sorting and filtering data are essential techniques to uncover hidden information or patterns. The clues suggest that the key to decoding the flag lies in manipulating the dataset in specific ways. Letâ€™s explore how to use some of pandas' powerful functionalities, such as `sort_values` and `groupby`, to potentially reveal the hidden flag.\n",
    "\n",
    "### Understanding Groupby Aggregations on a Pandas DataFrame\n",
    "\n",
    "The `groupby` method is incredibly useful for segmenting data into groups and applying a function to each group independently. This can help in summarizing or analyzing data separately within subsets defined by one or more attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf851c7-4520-4dba-9baf-5af93efbc085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the bear type and aggregate to the average `tune` value\n",
    "mean_tunes = df.groupby('bear')['tune'].mean()\n",
    "print(mean_tunes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669c78db-249f-4fa4-8295-8270a921564b",
   "metadata": {},
   "source": [
    "This code groups the data by bear type and calculates the average tune value for each type. Such aggregations can reveal differences in measurements across categories that might be significant in understanding the data better or even solving the challenge.\n",
    "\n",
    "### Sorting the Pandas DataFrame\n",
    "\n",
    "Sorting data can highlight the highest or lowest values in a dataset, or bring out the most significant entries according to a particular column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dce6831-6997-4c0c-b6f7-dad5213845e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the DataFrame by 'tune' in descending order to see the top values\n",
    "top_tunes = df.sort_values('tune').head(5)\n",
    "print(top_tunes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99231d76-30b3-49d7-9664-221d20a10223",
   "metadata": {},
   "source": [
    "This snippet sorts the entire DataFrame based on the tune column in descending order and displays the top 5 records. Sorting is particularly useful when you're looking for outliers or specific records that stand out in the dataset, which could be crucial in challenges like this where a single record might contain the key to the flag.\n",
    "\n",
    "### Filtering Data for Specific Conditions\n",
    "Sometimes, the clue to solving a challenge lies in isolating data based on specific conditions. Pandas allows for complex querying and filtering operations that can be pivotal in such scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75189399-94f2-40f3-abe2-904e1ab97923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering to find entries where 'tune' values are above a certain threshold\n",
    "high_tune_bears = df[df['tune'] > 90]\n",
    "print(high_tune_bears.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2edb4a4-a260-4427-9b21-3e46c6d39350",
   "metadata": {},
   "source": [
    "This filter operation selects records where the tune values exceed 90, possibly isolating important data points. Exploring the characteristics of these high tune entries could guide us towards the flag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bec3c3f9-3058-4bb7-9f86-205616ab98b6",
   "metadata": {},
   "source": [
    "### Applying Multiple Filters\n",
    "\n",
    "You can also apply multiple conditions to narrow down the data further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ecd9b-7b76-4c14-8cba-b84175020181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying multiple conditions to find a specific subset of data\n",
    "specific_bears = df[(df['tune'] > 50) & (df['bear'] == 'Kodiak')]\n",
    "print(specific_bears.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87a65ee-e233-47e3-885d-01c8a36d5cda",
   "metadata": {},
   "source": [
    "This example shows how to use multiple conditions to filter the data, which can be incredibly useful when trying to decode complex patterns or requirements set forth by a challenge.\n",
    "\n",
    "By understanding and utilizing these data manipulation techniques, you can explore various hypotheses or follow clues more effectively. Experimenting with different aggregations, sorting methods, and filters can unveil patterns that are not immediately obvious but are key to solving data-centric challenges.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb87179-94fe-400d-9dd8-2d21514f3fc3",
   "metadata": {},
   "source": [
    "## Step 4: Solving the Challenge\n",
    "\n",
    "Now that we've familiarized ourselves with the dataset and learned how to manipulate the data using various pandas functions, it's time to apply these skills to solve the challenge and decode the hidden flag.\n",
    "\n",
    "### Analyzing and Identifying Key Data\n",
    "\n",
    "The clues suggest that the secret word is encoded in a unique way related to the characteristics of each bear type at specific `tune` values. We hypothesize that sorting the data by 'tune' and examining the highest values for each bear type might reveal this secret word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f65ae7-3c1b-47b5-80dc-f7f3293440fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting the data by 'tune' in descending order to focus on the highest values\n",
    "sorted_data = df.sort_values('tune', ascending=False)\n",
    "sorted_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81933d53-c53e-428d-95d2-f784fd043818",
   "metadata": {},
   "source": [
    "### Extracting Critical Information\n",
    "\n",
    "Next, we utilize the `groupby` method combined with `head(1)` to capture the top entry for each bear type, which we suspect holds the parts of our hidden word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ca0ee2-3533-4516-846e-60b0931dbea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by 'bear' type and taking the top entry for each group based on 'tune' value\n",
    "top_bears = df.sort_values('tune', ascending=False).groupby('bear').head(1)\n",
    "top_bears = top_bears.sort_values('bear')  # Sorting by bear type for easier visualization\n",
    "print(top_bears)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eb027b-431a-4445-bc84-d8b273c86e9d",
   "metadata": {},
   "source": [
    "### Decoding the Flag\n",
    "\n",
    "After extracting the top entry for each bear type, we need to examine these entries closely. We suspect that the val column in these entries might hold the characters of the flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b336b89-5fb1-404c-9675-bfb329538d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting characters from the 'val' column\n",
    "characters = top_bears['val'].tolist()\n",
    "secret_word = ''.join(characters)\n",
    "print(\"Secret Word:\", secret_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7472c2-9c81-4df1-b8b8-3f5cb8620262",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_word = [c for c in secret_word if c not in ['{','}',' ']]\n",
    "secret_word = ''.join(secret_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24923e9-14aa-4d42-8d10-bce69fa69cd5",
   "metadata": {},
   "source": [
    "This operation gathers all the characters from the val column of the top entries, concatenating them to form the secret word. We then need to format this word according to the flag format provided in the challenge instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d6059-8f2e-4555-aeb7-740c0c989d04",
   "metadata": {},
   "source": [
    "## Submitting Our Findings to the Endpoint\n",
    "\n",
    "Finally, we submit the secret word to the challenge's scoring API to receive the flag. Here's how you can do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5cd35e-c1e8-476c-a1e1-81efb9de440a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def query(input_data):\n",
    "    response = requests.post(\n",
    "        \"https://bear.dev-crucible.dreadnode.io/score\",\n",
    "        headers={\"Authorization\": CRUCIBLE_API_KEY},\n",
    "        json={\"data\": input_data}\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "response = query(secret_word)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d935eb-0c0e-487d-95ae-201d6e2e26cd",
   "metadata": {},
   "source": [
    "## Submitting Our Flag\n",
    "\n",
    "You should see the flag returned above the starts with `gAAAA....` congradulations! You can now submit it to the crucible website to \n",
    "\n",
    "1. Uploading on the challenge page by clicking the \"Submit Flag\" button.\n",
    "2. Using the code provided below to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39e77f9-da3d-4ee1-abce-7c2f008be035",
   "metadata": {},
   "outputs": [],
   "source": [
    "response['flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fba00f7-a617-4184-b7e0-676a39627d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_flag(flag_value):\n",
    "    url = \"https://dev-crucible.dreadnode.io/api/submit-flag\"\n",
    "    headers={\"Authorization\": CRUCIBLE_API_KEY}\n",
    "    payload = {\n",
    "        \"challenge\": \"bear\",\n",
    "        \"flag\": flag_value\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        if response.json()['correct']:\n",
    "            print(\"The flag was correct. Congrats!\")\n",
    "        else:\n",
    "            print(\"The flag was incorrect. Keep trying!\")\n",
    "    else:\n",
    "        print(\"There was an error submitting your flag\")\n",
    "        print(response.text)\n",
    "\n",
    "flag_value = response['flag']\n",
    "r2 = submit_flag(flag_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9125ff-ab73-497c-b8c3-919d3710bd36",
   "metadata": {},
   "source": [
    "## Well Done!\n",
    "\n",
    "Congratulations on solving the challenge! Through this exercise, you've honed your skills in data analysis using pandas, learned to manipulate and interpret complex datasets, and applied these skills in a simulated AI security scenario. Keep practicing these techniques to further enhance your expertise in data-driven cybersecurity tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8e99e7-c3e1-4089-9ec2-b1bfde20802a",
   "metadata": {},
   "source": [
    "# Submitting the Flag\n",
    "\n",
    "You can use the below helper code to submit the flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a003b-d4b2-4972-94c7-40cd093c2e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_flag(flag, challenge=\"bear1\"):\n",
    "    url = \"https://dev-crucible.dreadnode.io/api/submit-flag\"\n",
    "    headers = {\"Authorization\": CRUCIBLE_API_KEY}\n",
    "    payload = {\"challenge\": challenge, \"flag\": flag}\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        if response.json().get(\"correct\") is True:\n",
    "            print(\"The flag was correct. Congrats!\")\n",
    "        else:\n",
    "            print(\"The flag was incorrect. Keep trying!\")\n",
    "    else:\n",
    "        print(\"There was an error submitting your flag\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd542d7e-06d7-4c2c-9370-98327cfd9dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_flag()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
