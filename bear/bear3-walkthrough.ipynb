{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a8af61-e32c-4605-8b12-5acbb5e26499",
   "metadata": {},
   "source": [
    "# Bear 3 - Model Fingerprinting\n",
    "\n",
    "Welcome to the \"Bear 3 - Model Fingerprinting\" challenge, where your skills in exploiting AI systems will be put to the test. In this tutorial, you'll learn how to determine the specific type of machine learning model being used by an API endpoint. Identifying a model's architecture and preprocessing steps is crucial for understanding its strengths and weaknesses. This knowledge enables a security professional to anticipate potential vulnerabilities, tailor attacks or defenses, and optimize their interactions with the model without excessive querying that could lead to detection or access denial.\n",
    "\n",
    "## Challenge Description\n",
    "\n",
    "In this challenge, you are provided with access to an image classifier hosted on a popular bear-themed social networking site. The site's API allows you to upload images and returns the probability that the depicted subject is a brown bear. Your task is to uncover the inner workings of this classifier:\n",
    "\n",
    "```\n",
    "You are given access to an image classifier hosted on a bear social networking site. If you send this endpoint an image, it will respond with the probability that the bear is a `brown bear`. You are interested in understanding exacly which model that this website is using so that you can run further experiments on it without needing to constantly trigger the endpoint, risking having your account banned.\n",
    "\n",
    "### Objective\n",
    "\n",
    "Your objective is to leverage the outputs from the API model to identify the exact image preprocessing and model being used on the bear social networking site. Once you believe you've identified the model being used you can unlock the flag by submitting the probabiliy of the second provided image `ping_pong.png` prediction of being a ping pong ball.\n",
    "```\n",
    "\n",
    "## Understanding Model Fingerprinting\n",
    "\n",
    "### Black Box vs. White Box Models\n",
    "- **Black Box Model**: In this context, a black box model is one where the internal architecture and parameters are unknown to you. You interact with it only through its API, observing inputs and outputs without access to the underlying code or weights. This is typical in real-world scenarios where security professionals must assess external systems.\n",
    "\n",
    "- **White Box Model**: Contrary to the black box, a white box model is fully exposed to the investigator. It includes complete access to the model’s architecture, weights, and even the training data. This scenario is ideal for internal audits and in-depth security assessments where transparency is required.\n",
    "\n",
    "In this tutorial, you will use techniques typically applied to black box scenarios to infer the white box details of the model based solely on its behavior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771db3cf-5807-4939-8449-0783267d1474",
   "metadata": {},
   "source": [
    "## Setup and Downloading Artifacts\n",
    "\n",
    "Before diving into the challenge, please ensure you have retrieved your personal API key from the following resource. We will use this API key to authenticate requests and download the necessary image files for analysis. These images can also be downloaded directly through the web interface if you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e32c17-f1b0-441f-96bf-c2a86486edec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place your CRUCIBLE API key here\n",
    "CRUCIBLE_API_KEY = \"YOUR_API_KEY\"\n",
    "\n",
    "# Import necessary libraries\n",
    "import requests\n",
    "from PIL import Image\n",
    "import base64\n",
    "import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4c5a08-54a0-4fe6-92c9-8ae6a187ebbd",
   "metadata": {},
   "source": [
    "### Downloading Image Files\n",
    "\n",
    "We provide two images for this challenge: 'brown_bear.png' and 'ping_pong.png'. The following script will automate their download using the provided API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac621cf-3353-4190-9bed-d0fd3fe319f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifacts = [\"brown_bear.png\", \"ping_pong.png\"]\n",
    "\n",
    "for artifact in artifacts:\n",
    "    url = f\"https://crucible.dreadnode.io/api/artifacts/bear3/{artifact}\"\n",
    "    headers = {\"Authorization\": CRUCIBLE_API_KEY}\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        with open(artifact, \"wb\") as file:\n",
    "            file.write(response.content)\n",
    "        print(f\"{artifact} was successfully downloaded\")\n",
    "    else:\n",
    "        print(\"Failed to download {artifact}: \", response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729c9636-d7a7-4d9d-a84e-fbce9a60f41f",
   "metadata": {},
   "source": [
    "### Verifying Download\n",
    "Ensure that the images are downloaded successfully by listing them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f70095f-6b5e-469f-8f83-5a4b29868b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -l | grep .png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aa968cc-4724-47cd-bd3c-d3f9553c0f0f",
   "metadata": {},
   "source": [
    "## Testing the endpoint\n",
    "\n",
    "To understand the behavior of the model behind the API, we will first visualize the provided images and then test them against the endpoint.\n",
    "\n",
    "### Displaying Images\n",
    "\n",
    "Let’s examine the images to confirm their content before sending them to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef3a6f9-2105-4cc0-b89a-121921955360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 'brown_bear.png' image\n",
    "im = Image.open(\"brown_bear.png\")\n",
    "display(im)\n",
    "\n",
    "# Display the 'ping_pong.png' image\n",
    "im = Image.open(\"ping_pong.png\")\n",
    "display(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae650a3-364e-462a-90ae-e36eab310d9b",
   "metadata": {},
   "source": [
    "### Sending Requests to the Endpoint\n",
    "\n",
    "We need to encode the images in base64 format before sending them through the API. Below is a demonstration of how to prepare and send a request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a3585e-22ae-433a-a06e-3b60b879c53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image and b64 encode to send to the endpoint\n",
    "def get_encoded_image(image_filename):\n",
    "    with open(image_filename, \"rb\") as f:\n",
    "        image = base64.b64encode(f.read())\n",
    "    return image\n",
    "\n",
    "\n",
    "def query(input_data):\n",
    "    response = requests.post(\n",
    "        \"https://bear3.crucible.dreadnode.io/score\",\n",
    "        headers={\"Authorization\": CRUCIBLE_API_KEY},\n",
    "        json={\"data\": input_data},\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "# Test query with 'brown_bear.png'\n",
    "image_data = get_encoded_image(\"brown_bear.png\")\n",
    "response = query(image_data.decode())\n",
    "print(\"Response for 'brown_bear.png': \", response)\n",
    "\n",
    "# Test query with 'ping_pong.png'\n",
    "image_data = get_encoded_image(\"ping_pong.png\")\n",
    "response = query(image_data.decode())\n",
    "print(\"Response for 'ping_pong.png': \", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32c5738-d8d7-4b1c-939b-30e67c2de24f",
   "metadata": {},
   "source": [
    "This testing section allows you to see how the API responds to images that the model identifies as a brown bear and how it handles images of other subjects. It sets the stage for deeper analysis as you proceed to model fingerprinting in the following sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6996f615-4506-42b9-bb16-4349c93c0885",
   "metadata": {},
   "source": [
    "## Fingerprinting Approach.\n",
    "\n",
    "The core objective of this tutorial is to identify the underlying model used by the Bear3 API endpoint. Ideally, we aim to replicate the model's entire processing pipeline so that our local setup can predict outcomes as accurately as the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e76b00-a93a-4fa4-a7ed-5bfda3fae154",
   "metadata": {},
   "source": [
    "## Probe the model endpoint\n",
    "\n",
    "Model fingerprinting involves determining the specifics of the model by observing how it responds to various inputs. This can be achieved through multiple strategies:\n",
    "\n",
    "1. **Using Random Images**: Observing how the model reacts to completely random images.\n",
    "2. **Applying Minor Modifications**: Making slight alterations to known images and studying the model's responses.\n",
    "3. **Utilizing Random Noise**: Sending images composed of random noise and analyzing the outputs.\n",
    "4. Any other method that would examine the input/output relationship of the endpoint.\n",
    "\n",
    "For this tutorial, we'll use a more structured approach by rotating a known image and observing how the model's confidence scores change. This will provide insights into the model's robustness and handling of image transformations.\n",
    "\n",
    "### Experiment Setup\n",
    "\n",
    "We'll use the brown_bear.png image, apply different rotations, and record the model's predictions in a pandas DataFrame. This method allows us to visualize the model's sensitivity to image orientation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211dc55e-62fc-47d6-8be6-01e76254bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import io\n",
    "import base64\n",
    "\n",
    "# Initialize tracking DataFrame\n",
    "tracking = pd.DataFrame()\n",
    "\n",
    "# Setup plot for visualizing responses\n",
    "fig, axs = plt.subplots(2, 5, figsize=(10, 5))\n",
    "axs = axs.flatten()\n",
    "\n",
    "# Load and display the base image\n",
    "bear_image = Image.open(\"brown_bear.png\")\n",
    "for i, angle in enumerate(range(0, 360, 36)):\n",
    "    # Rotate image and encode it to base64\n",
    "    rotated_image = bear_image.rotate(angle)\n",
    "    buffered = io.BytesIO()\n",
    "    rotated_image.save(buffered, format=\"PNG\")\n",
    "    rotated_image_base64 = base64.b64encode(buffered.getvalue()).decode(\"utf-8\")\n",
    "\n",
    "    # Query the model endpoint with the rotated image\n",
    "    response = query(rotated_image_base64)\n",
    "    print(f\"Image rotated at angle {angle}°, score: {response}\")\n",
    "\n",
    "    # Store response in DataFrame\n",
    "    tracking.loc[i, \"base_image\"] = \"brown_bear.png\"\n",
    "    tracking.loc[i, \"rotation\"] = angle\n",
    "    tracking.loc[i, \"brown_bear_score\"] = response[\"brown bear\"]\n",
    "\n",
    "    # Display the rotated image and score\n",
    "    axs[i].imshow(rotated_image)\n",
    "    axs[i].set_title(f'Score: {response[\"brown bear\"]:0.4f}')\n",
    "    axs[i].axis(\"off\")\n",
    "plt.show()\n",
    "\n",
    "# Example output logs\n",
    "print(tracking.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffcc0a1-0980-4fde-bc13-0c522de8f592",
   "metadata": {},
   "source": [
    "## Experiment Result Analysis\n",
    "\n",
    "By rotating the image and observing the model's response, we can start to understand its handling of orientation changes, which might suggest specific characteristics of the model's training or architecture. For instance, a significant drop in confidence as the image rotates away from an upright position could indicate a lack of rotational invariance, which is common in many image recognition models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974387c2-755f-4e9f-9f11-bcf0bfd265fb",
   "metadata": {},
   "source": [
    "## Pretrained Image Models\n",
    "\n",
    "### Understanding ImageNet\n",
    "\n",
    "Many image recognition models are pretrained on ImageNet, a vast dataset used in computer vision for training and benchmarking. ImageNet contains over a million labeled images spanning thousands of categories. One of these categories includes \"brown bear,\" which is crucial for our analysis because it directly relates to the challenge at hand.\n",
    "\n",
    "For further exploration of the \"brown bear\" category in ImageNet, you can visit: [Salient ImageNet - Brown Bear Class.](https://salient-imagenet.cs.umd.edu/explore/class_294/feature_140.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c910b398-46d0-4d16-ab80-b39abf3e6472",
   "metadata": {},
   "source": [
    "# Setting Up Pretrained Models\n",
    "\n",
    "For this challenge, we will utilize models available through the PyTorch 'timm' library. Understanding the general workflow of image classifiers will aid in replicating the endpoint's model:\n",
    "\n",
    "1. **Image Preprocessing**: The image is transformed into a numerical array (HxWxC format, where H is height, W is width, and C is channels representing RGB values).\n",
    "2. **Normalization**: The pixel values are standardized to ensure they match the model’s expected input range, typically using a mean and standard deviation that align with the ImageNet training data.\n",
    "3. **Model Inference**: The processed image array is fed into the model, which outputs predictions across 1,000 classes.\n",
    "\n",
    "Below, we provide the preprocessing steps and the function to predict using any given model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59953d95-08c1-4311-87c8-c66a4c2ee7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "# Function to load an image and transform it for model inference\n",
    "def load_and_transform_image(image_path):\n",
    "    transform = transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(224),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    )\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "\n",
    "# Function to perform prediction using a specified model\n",
    "def predict_image(model_name, image_tensor):\n",
    "    model = timm.create_model(model_name, pretrained=True)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(image_tensor)\n",
    "    return logits.argmax(dim=1), logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16c79a-6322-476d-9de2-62084a50e46c",
   "metadata": {},
   "source": [
    "### Testing Pretrained Models\n",
    "\n",
    "Let's apply these functions to predict the category of the `brown_bear.png` image using different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a61ceb-522e-4c84-a943-fa5b9abe597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = load_and_transform_image(\"brown_bear.png\")\n",
    "model_names = [\"mobilenetv3_large_100\", \"efficientnet_b0\", \"resnet18\"]\n",
    "BROWN_BEAR_INDEX = 294  # Index for brown bear in ImageNet\n",
    "\n",
    "# Test each model and print out the probability of 'brown bear'\n",
    "for model_name in model_names:\n",
    "    prediction, logits = predict_image(model_name, image_tensor)\n",
    "    probs = torch.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    print(f\"Prediction from {model_name}: {prediction}\")\n",
    "    print(f\"Brown bear probability: {probs[0][BROWN_BEAR_INDEX]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaab5516-c4a9-4077-9781-8fe3260eafae",
   "metadata": {},
   "source": [
    "The output from these models will help us identify which one resembles the behavior of the Bear3 API endpoint the closest. By comparing these results, we can determine the model that most likely powers the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8830d3b0-0247-40c1-ae57-e1658fb481ec",
   "metadata": {},
   "source": [
    "# Fingerprinting offline models\n",
    "\n",
    "Having established a baseline of how our pretrained models predict the 'brown bear' class, we can further refine our model identification process. This involves comparing the behavior of our local models against the model behind the Bear3 API using the previously rotated images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762cdae2-8de3-4e39-9919-b9ae77f659ef",
   "metadata": {},
   "source": [
    "## Running Inference on Rotated Images\n",
    "\n",
    "To systematically compare the models, we'll re-use the rotated images, testing each one with our selected pretrained models. This will help us evaluate how closely each model's responses match the API's output over a range of image orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2864e962-66ed-45bd-a3ce-01342ec04df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-using the rotated images to test each offline model\n",
    "for i, angle in enumerate(range(0, 360, 36)):\n",
    "    rotated_image = bear_image.rotate(angle)  # Rotate image\n",
    "    rotated_image.save(\"temp.png\")  # Save as a temporary file\n",
    "    image_tensor = load_and_transform_image(\"temp.png\")  # Transform image for model inference\n",
    "\n",
    "    for model_name in model_names:\n",
    "        prediction, logits = predict_image(model_name, image_tensor)\n",
    "        probs = torch.softmax(logits, dim=1)\n",
    "        # Store each model's probability for the brown bear class in tracking DataFrame\n",
    "        tracking.loc[i, f\"{model_name}_score\"] = probs[0][BROWN_BEAR_INDEX].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3a9ded-61ab-4fa4-8edd-6a405b380051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the results for visual comparison\n",
    "fig, axs = plt.subplots(1, 2, figsize=(15, 5))\n",
    "for model_name, color in zip(model_names, [\"blue\", \"red\", \"orange\"]):\n",
    "    tracking.plot(\n",
    "        x=\"rotation\",\n",
    "        y=f\"{model_name}_score\",\n",
    "        style=\"-.\",\n",
    "        label=f\"{model_name} predictions\",\n",
    "        ax=axs[0],\n",
    "        color=color\n",
    "    )\n",
    "\n",
    "tracking.plot(\n",
    "    x=\"rotation\",\n",
    "    y=\"brown_bear_score\",\n",
    "    style=\"-\",\n",
    "    label=\"API predictions\",\n",
    "    ax=axs[1],\n",
    "    color=\"black\"\n",
    ")\n",
    "\n",
    "axs[0].set_title(\"Model Predictions by Rotation\")\n",
    "axs[1].set_title(\"API Predictions by Rotation\")\n",
    "axs[0].set_ylabel(\"Probability\")\n",
    "axs[1].set_ylabel(\"Probability\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cad480-f689-48a8-ac8d-22ee1da037f1",
   "metadata": {},
   "source": [
    "## Analyzing Correlations\n",
    "\n",
    "To quantify how closely each model's predictions correlate with the API responses, we compute the correlation coefficient for each model relative to the API. A higher correlation suggests a closer match to the underlying model used by the API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f05d7-90ac-4eb1-811d-940eb2eabc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Calculate and print the correlation of each model's scores with the API scores\n",
    "for model_name in model_names:\n",
    "    correlation = np.corrcoef(tracking['brown_bear_score'], tracking[f'{model_name}_score'])[0, 1]\n",
    "    print(f\"Correlation of {model_name} with API: {correlation:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4c0f6a-7c3b-478e-9bd1-03dc7e8efa83",
   "metadata": {},
   "source": [
    "## Local vs API Model Comparison\n",
    "\n",
    "Upon analyzing the predictions from the `resnet18` model across various image rotations, we observed a strong alignment with the API's responses. This high degree of similarity across all tested conditions strongly indicates that the Bear3 API likely uses a model similar to resnet18."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5269ed2-d0ec-4796-961e-d7c51de7dde8",
   "metadata": {},
   "source": [
    "# Getting the Flag\n",
    "\n",
    "## Predicting an Unseen Class\n",
    "\n",
    "With the model identified, the next step involves using it to predict a category not explicitly related to the primary task. According to the challenge, we should now predict the probability that an image of a ping pong ball (`ping_pong.png`) is recognized as something else. In ImageNet, the \"ping pong ball\" category is indexed at 722.\n",
    "\n",
    "For a deeper look at this class, refer to: [Salient ImageNet - Ping Pong Ball Class](https://salient-imagenet.cs.umd.edu/explore/class_722/feature_352.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b5a8f-4ba2-49f4-b7e8-93405aa4b725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and transform the image\n",
    "image_tensor = load_and_transform_image(\"ping_pong.png\")\n",
    "# Make predictions using the identified model\n",
    "prediction, logits = predict_image('resnet18', image_tensor)\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "\n",
    "PING_PONG_IDX = 722\n",
    "ping_pong_prediction = probs[0][PING_PONG_IDX].item()\n",
    "print(\"Predicted resnet18 probability for 'ping pong ball':\", ping_pong_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34091b7-dc73-4617-a862-cc3ade1dfd59",
   "metadata": {},
   "source": [
    "### Submitting the Prediction to the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e7a9bb-659b-4df2-b1ce-034f59bcc9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to send the predicted probability to the API and get the flag\n",
    "def get_flag(pingpong_prob):\n",
    "    response = requests.post(\n",
    "        \"https://bear3.crucible.dreadnode.io/score\",\n",
    "        headers={\"Authorization\": CRUCIBLE_API_KEY},\n",
    "        json={\"pingpong\": pingpong_prob},\n",
    "    )\n",
    "    return response.json()\n",
    "\n",
    "# Fetch the flag using the predicted probability\n",
    "flag_response = get_flag(ping_pong_prediction)\n",
    "print(\"Flag Response:\", flag_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c428bef2-f625-4d4a-8512-bf4a8cdeb74f",
   "metadata": {},
   "source": [
    "## Submit The Flag\n",
    "\n",
    "Once you have the flag you can use the following function to submit the flag to Crucible. Alternatively you can submit it direction on the Crucible website."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce71f0b3-ee7d-4755-8448-0ff153ab5a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submit_flag(flag, challenge=\"bear3\"):\n",
    "    url = \"https://crucible.dreadnode.io/api/submit-flag\"\n",
    "    headers = {\"Authorization\": CRUCIBLE_API_KEY}\n",
    "    payload = {\"challenge\": challenge, \"flag\": flag}\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    if response.status_code == 200:\n",
    "        if response.json().get(\"correct\") is True:\n",
    "            print(\"The flag was correct. Congrats!\")\n",
    "        else:\n",
    "            print(\"The flag was incorrect. Keep trying!\")\n",
    "    else:\n",
    "        print(\"There was an error submitting your flag\")\n",
    "        print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5c057e-d705-4a53-896a-0e38f8825ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "submit_flag(flag_response[\"flag\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de54c921-54ec-4347-978d-44ea7beaabb2",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this challenge, we successfully identified the model used by an API by comparing its behavior to that of known pretrained models. We demonstrated the practical application of model fingerprinting techniques, which are essential in scenarios where understanding an API's behavior can be crucial for security testing.\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- **Model Understanding**: Deep knowledge of how models process inputs can reveal vulnerabilities or features not immediately apparent.\n",
    "- **Adaptability**: Each challenge might require different strategies. Flexibility in approach and methodology is crucial.\n",
    "- **Continuous Learning**: New models and techniques are regularly developed; staying updated with the latest in machine learning and security research is key to success.\n",
    "\n",
    "Remember, real-world applications might not always provide as clear-cut results, and models in production could be customized, requiring more nuanced approaches."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
